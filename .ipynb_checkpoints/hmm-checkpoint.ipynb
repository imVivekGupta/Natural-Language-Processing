{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Labeling in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the transition, start and emission matrix . The states stand for high and low.  The HMM model is given in the assignment itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "P= np.array([[0.6, 0.4],[0.5,0.5]])\n",
    "\n",
    "S= np.array([0.5, 0.5])\n",
    "\n",
    "O= np.array([[0.3,0.2,0.2,0.3],[0.2,0.3,0.3,0.2]])\n",
    "\n",
    "state={}\n",
    "state[0]='L'\n",
    "state[1]='H'\n",
    "\n",
    "DNA={}\n",
    "DNA['A']=0\n",
    "DNA['C']=1\n",
    "DNA['G']=2\n",
    "DNA['T']=3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A stupid attempt to show you why the exhaustive search is a bad, bad option for HMM modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import time \n",
    "def exhaustive_search(sequence):\n",
    "    \n",
    "    M= len(sequence)\n",
    "    state_len= len(S)\n",
    "    \n",
    "    # track the best sequence and its score\n",
    "    best=(None,float('-inf'))\n",
    "    \n",
    "    # basically loop will run for |states|^M \n",
    "    for ss in product(range(state_len),repeat=M):\n",
    "        \n",
    "        score= S[ss[0]]*O[ss[0],DNA[sequence[0]]]\n",
    "        \n",
    "        for i in range(1,M):\n",
    "            score*= P[ss[i-1],ss[i]]*O[ss[i],DNA[sequence[i]]]\n",
    "            \n",
    "        \n",
    "        #print(','.join([state[k] for k in ss]),score)\n",
    "    \n",
    "        if score > best[1]:\n",
    "            best= (ss,score)\n",
    "    \n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the sequence GGC of length 3 time taken was 0.105s\n",
      "The sequence H,H,H gave the best score of 0.003375\n",
      "\n",
      "\n",
      "For the sequence GGCAAGATCAT of length 11 time taken was 0.052s\n",
      "The sequence H,H,H,L,L,L,L,L,L,L,L gave the best score of 1.377495072e-09\n",
      "\n",
      "\n",
      "For the sequence GAGAGGAGAGAGAGAGAGA of length 19 time taken was 21.034s\n",
      "The sequence H,L,L,L,H,H,L,L,L,L,L,L,L,L,L,L,L,L,L gave the best score of 1.3326697514e-16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequences=['GGC','GGCAAGATCAT','GAGAGGAGAGAGAGAGAGA']\n",
    "\n",
    "import time\n",
    "for sequence in sequences:\n",
    "    \n",
    "    t=time.time()\n",
    "    best=exhaustive_search(sequence)\n",
    "    t2=time.time()-t\n",
    "    \n",
    "    print('For the sequence '+ sequence+ ' of length '+ str(len(sequence))+' time taken was '+ str(round(t2,3))+'s' )\n",
    "    print('The sequence '+ ','.join([state[k] for k in best[0]])+ ' gave the best score of '+ str(best[1]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for this assignment: Brown corpus tagged with the Universal Tagset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This will be your training set. The remaining 100 sentences will be used as your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "corpus = brown.tagged_sents(tagset='universal')[:-100]\n",
    "\n",
    "start_mat = {}\n",
    "transmission_mat={}\n",
    "emission_mat={}\n",
    "\n",
    "for sent in corpus:\n",
    "    if sent[0][1] not in start_mat:\n",
    "        start_mat[sent[0][1]] = 0\n",
    "    start_mat[sent[0][1]] += 1\n",
    "    for i in range(len(sent)):\n",
    "        elem = sent[i]\n",
    "        w = elem[0].lower()\n",
    "        tag= elem[1]\n",
    "\n",
    "        if tag not in emission_mat:\n",
    "            emission_mat[tag]= {w:1}\n",
    "        elif w not in emission_mat[tag]:\n",
    "            emission_mat[tag][w] = 1\n",
    "        else:\n",
    "            emission_mat[tag][w] += 1\n",
    "\n",
    "        if i == len(sent)-1:\n",
    "            next_state = 'stop'\n",
    "        else:\n",
    "            next_state = sent[i+1][1]\n",
    "            \n",
    "        if tag not in transmission_mat:\n",
    "            transmission_mat[tag] = {next_state : 1}\n",
    "        elif next_state not in transmission_mat[tag]:\n",
    "            transmission_mat[tag][next_state] = 1\n",
    "        else:\n",
    "            transmission_mat[tag][next_state] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0.08901118099231309,\n",
       " 'ADJ': 0.03434661076170511,\n",
       " 'ADP': 0.12283368273934313,\n",
       " 'ADV': 0.09117749825296996,\n",
       " 'CONJ': 0.049161425576519924,\n",
       " 'DET': 0.2133997204751922,\n",
       " 'NOUN': 0.14129979035639414,\n",
       " 'NUM': 0.01678895877009085,\n",
       " 'PRON': 0.15971348707197766,\n",
       " 'PRT': 0.036652690426275336,\n",
       " 'VERB': 0.04509084556254368,\n",
       " 'X': 0.0005241090146750525}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "total = sum(start_mat.values())            \n",
    "for state in start_mat:\n",
    "    start_mat[state] /= total\n",
    "    \n",
    "for state in emission_mat:\n",
    "    total = sum(emission_mat[state].values())\n",
    "    for w in emission_mat[state]:\n",
    "        emission_mat[state][w] = emission_mat[state][w]/total\n",
    "        \n",
    "for state in transmission_mat:\n",
    "    total = sum(transmission_mat[state].values())\n",
    "    for next_state in transmission_mat[state]:\n",
    "        transmission_mat[state][next_state] /= total\n",
    "        \n",
    "        \n",
    "test_data= brown.tagged_sents(tagset='universal')[-100:]\n",
    "\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_viterbi(V,new_state,observation):\n",
    "    best = (0,new_state)\n",
    "    for old_state in V:\n",
    "        if observation not in emission_mat[new_state]:\n",
    "            if new_state not in transmission_mat[old_state]:\n",
    "                prob = V[old_state]\n",
    "            else:\n",
    "                prob = V[old_state]*transmission_mat[old_state][new_state]\n",
    "        else:\n",
    "            if new_state not in transmission_mat[old_state]:\n",
    "                prob = V[old_state]*emission_mat[new_state][observation]\n",
    "            else:\n",
    "                prob = V[old_state]*transmission_mat[old_state][new_state]*emission_mat[new_state][observation]\n",
    "        if prob > best[0]:\n",
    "            best = (prob,old_state)\n",
    "    return best            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sent(sent):\n",
    "    tokens = [i.lower() for i in sent.split()]\n",
    "    \n",
    "    # initialize\n",
    "    V = dict()\n",
    "    B = list()\n",
    "    #B.append({})\n",
    "    for state in emission_mat:\n",
    "        try:\n",
    "            V[state] = (start_mat[state]*emission_mat[state][tokens[0]])\n",
    "        except:\n",
    "            V[state] = start_mat[state]\n",
    "        #B[0][state] = 'start'\n",
    "    \n",
    "    # recurse\n",
    "    for token in tokens[1:]:\n",
    "        V_updated = dict()\n",
    "        B.append({})\n",
    "        for state in emission_mat:\n",
    "            V_updated[state], B[-1][state] = update_viterbi(V,state,token)\n",
    "        V = V_updated\n",
    "    \n",
    "    # terminate\n",
    "    best = (0,'.')\n",
    "    for state in V:\n",
    "        prob = V[state]*transmission_mat[state]['stop']\n",
    "        if prob>best[0]:\n",
    "            best = (prob,state)\n",
    "    \n",
    "    # back-track\n",
    "    current_state = best[1]\n",
    "    pos = [current_state]\n",
    "    B.reverse()\n",
    "    for b in B:\n",
    "        current_state = b[current_state]\n",
    "        pos.append(current_state)\n",
    "    pos.reverse()\n",
    "    \n",
    "    pos_seq = list(zip(tokens,pos))\n",
    "    return pos_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct_tags = 0\n",
    "    total_tags = 0\n",
    "    diff_tokens = 0\n",
    "    for sent in test_data:\n",
    "        actual_sent = ' '.join([t[0] for t in sent])\n",
    "        #print(actual_sent)\n",
    "        pos_seq = tag_sent(actual_sent)\n",
    "        #print(pos_seq)\n",
    "        for model_tag, actual_tag in zip(pos_seq,sent):\n",
    "            #print(model_tag, actual_tag)\n",
    "            if(model_tag[0] == actual_tag[0].lower()):\n",
    "                if (model_tag[1]==actual_tag[1]):\n",
    "                    correct_tags += 1\n",
    "            else:\n",
    "                diff_tokens += 1\n",
    "        total_tags += len(sent)\n",
    "    acc = correct_tags/total_tags\n",
    "    return acc,diff_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.054598908021839566, 0)\n"
     ]
    }
   ],
   "source": [
    "print(test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('from', 'ADP'),\n",
       " ('what', 'DET'),\n",
       " ('i', 'PRON'),\n",
       " ('was', 'VERB'),\n",
       " ('able', 'ADJ'),\n",
       " ('to', 'ADP'),\n",
       " ('gauge', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('swift', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('greedy', 'ADJ'),\n",
       " ('glance', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('the', '.'),\n",
       " ('figure', '.'),\n",
       " ('inside', '.'),\n",
       " ('the', '.'),\n",
       " ('coral-colored', '.'),\n",
       " ('boucle', '.'),\n",
       " ('dress', '.'),\n",
       " ('was', '.'),\n",
       " ('stupefying', '.'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_sent('From what I was able to gauge in a swift , greedy glance , the figure inside the coral-colored boucle dress was stupefying .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55907\n",
      "12\n",
      "[[('you', 'PRON'), (\"can't\", 'VERB'), ('very', 'ADV'), ('well', 'ADV'), ('sidle', 'VERB'), ('up', 'ADP'), ('to', 'ADP'), ('people', 'NOUN'), ('on', 'ADP'), ('the', 'DET'), ('street', 'NOUN'), ('and', 'CONJ'), ('ask', 'VERB'), ('if', 'ADP'), ('they', 'PRON'), ('want', 'VERB'), ('to', 'PRT'), ('buy', 'VERB'), ('a', 'DET'), ('hot', 'ADJ'), ('Bodhisattva', 'NOUN'), ('.', '.')], [('Additionally', 'ADV'), (',', '.'), ('since', 'ADP'), (\"you're\", 'PRT'), ('going', 'VERB'), ('to', 'PRT'), ('be', 'VERB'), ('hors', 'X'), ('de', 'X'), ('combat', 'X'), ('pretty', 'ADV'), ('soon', 'ADV'), ('with', 'ADP'), ('sprue', 'NOUN'), (',', '.'), ('yaws', 'NOUN'), (',', '.'), ('Delhi', 'NOUN'), ('boil', 'NOUN'), (',', '.'), ('the', 'DET'), ('Granville', 'NOUN'), ('wilt', 'NOUN'), (',', '.'), ('liver', 'NOUN'), ('fluke', 'NOUN'), (',', '.'), ('bilharziasis', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('a', 'DET'), ('host', 'NOUN'), ('of', 'ADP'), ('other', 'ADJ'), ('complications', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('hex', 'NOUN'), (\"you've\", 'PRT'), ('aroused', 'VERB'), (',', '.'), ('you', 'PRON'), (\"mustn't\", 'VERB'), ('expect', 'VERB'), ('to', 'PRT'), ('be', 'VERB'), ('lionized', 'VERB'), ('socially', 'ADV'), ('.', '.')], [('My', 'DET'), ('advice', 'NOUN'), (',', '.'), ('if', 'ADP'), ('you', 'PRON'), ('live', 'VERB'), ('long', 'ADJ'), ('enough', 'ADV'), ('to', 'PRT'), ('continue', 'VERB'), ('your', 'DET'), ('vocation', 'NOUN'), (',', '.'), ('is', 'VERB'), ('that', 'ADP'), ('the', 'DET'), ('next', 'ADJ'), ('time', 'NOUN'), (\"you're\", 'PRT'), ('attracted', 'VERB'), ('by', 'ADP'), ('the', 'DET'), ('exotic', 'ADJ'), (',', '.'), ('pass', 'VERB'), ('it', 'PRON'), ('up', 'PRT'), ('--', '.'), (\"it's\", 'PRT'), ('nothing', 'NOUN'), ('but', 'CONJ'), ('a', 'DET'), ('headache', 'NOUN'), ('.', '.')], [('As', 'ADP'), ('you', 'PRON'), ('can', 'VERB'), ('count', 'VERB'), ('on', 'ADP'), ('me', 'PRON'), ('to', 'PRT'), ('do', 'VERB'), ('the', 'DET'), ('same', 'ADJ'), ('.', '.')], [('Compassionately', 'ADV'), ('yours', 'PRON'), (',', '.')], [('S.', 'NOUN'), ('J.', 'NOUN'), ('Perelman', 'NOUN')], [('revulsion', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('desert', 'NOUN')], [('the', 'DET'), ('doors', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('D', 'NOUN'), ('train', 'NOUN'), ('slid', 'VERB'), ('shut', 'VERB'), (',', '.'), ('and', 'CONJ'), ('as', 'ADP'), ('I', 'PRON'), ('dropped', 'VERB'), ('into', 'ADP'), ('a', 'DET'), ('seat', 'NOUN'), ('and', 'CONJ'), (',', '.'), ('exhaling', 'VERB'), (',', '.'), ('looked', 'VERB'), ('up', 'PRT'), ('across', 'ADP'), ('the', 'DET'), ('aisle', 'NOUN'), (',', '.'), ('the', 'DET'), ('whole', 'ADJ'), ('aviary', 'NOUN'), ('in', 'ADP'), ('my', 'DET'), ('head', 'NOUN'), ('burst', 'VERB'), ('into', 'ADP'), ('song', 'NOUN'), ('.', '.')], [('She', 'PRON'), ('was', 'VERB'), ('a', 'DET'), ('living', 'VERB'), ('doll', 'NOUN'), ('and', 'CONJ'), ('no', 'DET'), ('mistake', 'NOUN'), ('--', '.'), ('the', 'DET'), ('blue-black', 'ADJ'), ('bang', 'NOUN'), (',', '.'), ('the', 'DET'), ('wide', 'ADJ'), ('cheekbones', 'NOUN'), (',', '.'), ('olive-flushed', 'ADJ'), (',', '.'), ('that', 'PRON'), ('betrayed', 'VERB'), ('the', 'DET'), ('Cherokee', 'NOUN'), ('strain', 'NOUN'), ('in', 'ADP'), ('her', 'DET'), ('Midwestern', 'ADJ'), ('lineage', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('the', 'DET'), ('mouth', 'NOUN'), ('whose', 'DET'), ('only', 'ADJ'), ('fault', 'NOUN'), (',', '.'), ('in', 'ADP'), ('the', 'DET'), (\"novelist's\", 'NOUN'), ('carping', 'VERB'), ('phrase', 'NOUN'), (',', '.'), ('was', 'VERB'), ('that', 'ADP'), ('the', 'DET'), ('lower', 'ADJ'), ('lip', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('trifle', 'NOUN'), ('too', 'ADV'), ('voluptuous', 'ADJ'), ('.', '.')], [('From', 'ADP'), ('what', 'DET'), ('I', 'PRON'), ('was', 'VERB'), ('able', 'ADJ'), ('to', 'ADP'), ('gauge', 'NOUN'), ('in', 'ADP'), ('a', 'DET'), ('swift', 'ADJ'), (',', '.'), ('greedy', 'ADJ'), ('glance', 'NOUN'), (',', '.'), ('the', 'DET'), ('figure', 'NOUN'), ('inside', 'ADP'), ('the', 'DET'), ('coral-colored', 'ADJ'), ('boucle', 'NOUN'), ('dress', 'NOUN'), ('was', 'VERB'), ('stupefying', 'VERB'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "corpus = brown.tagged_sents(tagset='universal')[:-100]\n",
    "\n",
    "tag_dict={}\n",
    "word_dict={}\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        w = elem[0]\n",
    "        tag= elem[1]\n",
    "\n",
    "        if w not in word_dict:\n",
    "            word_dict[w]=0\n",
    "\n",
    "        if tag not in tag_dict:\n",
    "            tag_dict[tag]=0\n",
    "\n",
    "        word_dict[w]+=1\n",
    "        tag_dict[tag]+=1\n",
    "\n",
    "print(len(word_dict))\n",
    "print(len(tag_dict))\n",
    "        \n",
    "test_data= brown.tagged_sents(tagset='universal')[-10:]\n",
    "\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module to implement CRF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pip3 install sklearn-crfsuite # install this please\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "train_sents= corpus\n",
    "\n",
    "def word2features(sent,i):\n",
    "    word = sent[i][0]\n",
    "    \n",
    "    features ={\n",
    "    'bias': 1.0,\n",
    "    }\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent,i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for i,label in sent]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=[sent2features(s) for s in train_sents]\n",
    "y_train=[sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test=[sent2features(s) for s in test_data]\n",
    "y_test=[sent2labels(s) for s in test_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12985271687027178"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "labels=list(crf.classes_)\n",
    "\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .      0.800     0.242     0.372        33\n",
      "          X      0.023     1.000     0.044         3\n",
      "        ADJ      0.000     0.000     0.000        18\n",
      "        ADP      0.179     0.185     0.182        27\n",
      "        ADV      0.000     0.000     0.000         9\n",
      "       VERB      0.000     0.000     0.000        35\n",
      "        DET      0.121     0.121     0.121        33\n",
      "       CONJ      0.000     0.000     0.000         7\n",
      "       NOUN      0.242     0.157     0.190        51\n",
      "       PRON      0.000     0.000     0.000        12\n",
      "        PRT      0.000     0.000     0.000        11\n",
      "        NUM      0.000     0.000     0.000         0\n",
      "\n",
      "avg / total      0.199     0.117     0.130       239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
