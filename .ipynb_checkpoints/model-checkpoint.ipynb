{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build unigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import math\n",
    "from nltk.corpus import brown\n",
    "from collections import Counter\n",
    "from nltk import bigrams, ngrams, trigrams\n",
    "import numpy as np\n",
    "\n",
    "data = brown.sents()[:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    processed_data = []\n",
    "    for sentence in data:\n",
    "        new_sent = []\n",
    "        for word in sentence:\n",
    "            new_word = ''.join(re.findall('[a-z]+',word.lower()))\n",
    "            if(new_word != ''):\n",
    "                new_sent.append(new_word)\n",
    "        if(len(new_sent)!=0):\n",
    "            processed_data.append(new_sent)\n",
    "    return processed_data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentences = []\n",
    "outfile = open('./output.txt','w')\n",
    "with open('./input.txt','r') as infile:\n",
    "    test_sentences = [line.split() for line in infile.readlines()]\n",
    "    \n",
    "test_sentences = preprocess(test_sentences)\n",
    "test_sentences = [' '.join(sent) for sent in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigrams = []\n",
    "processed_data = preprocess(data)\n",
    "for sent in processed_data:\n",
    "    unigrams.extend(sent)\n",
    "    \n",
    "unigram_counts=Counter(unigrams)\n",
    "unigram_total=len(unigrams)\n",
    "unigram_model = {}\n",
    "\n",
    "for word in unigram_counts:\n",
    "    unigram_model[word] = unigram_counts[word]/unigram_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build bigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bigrams(sentences):\n",
    "    model={}\n",
    "    for sent in sentences:\n",
    "         for w1,w2 in ngrams(sent,2, pad_left=True,pad_right=True):\n",
    "            if w1 not in model:\n",
    "                model[w1]={}\n",
    "            if w2 not in model[w1]:\n",
    "                model[w1][w2]=0\n",
    "            model[w1][w2]+=1     \n",
    "    return model\n",
    "\n",
    "bigram_counts= get_bigrams(processed_data)\n",
    "bigram_model = copy.deepcopy(bigram_counts)\n",
    "\n",
    "for w1 in bigram_model:\n",
    "        tot_count=float(sum(bigram_model[w1].values()))\n",
    "        for w2 in bigram_model[w1]:\n",
    "            bigram_model[w1][w2]/=tot_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build trigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_trigrams(sentences):\n",
    "    model={}\n",
    "    for sent in sentences:\n",
    "         for w1,w2,w3 in ngrams(sent,3, pad_left=True,pad_right=True):\n",
    "            if (w1,w2) not in model:\n",
    "                model[(w1,w2)]={}\n",
    "            if w3 not in model[(w1,w2)]:\n",
    "                model[(w1,w2)][w3]=0\n",
    "            model[(w1,w2)][w3]+=1     \n",
    "    return model\n",
    "\n",
    "trigram_counts= get_trigrams(processed_data)\n",
    "trigram_model = copy.deepcopy(trigram_counts)\n",
    "\n",
    "for (w1,w2) in trigram_model:\n",
    "        tot_count=float(sum(trigram_model[(w1,w2)].values()))\n",
    "        for w3 in trigram_model[(w1,w2)]:\n",
    "            trigram_model[(w1,w2)][w3]/=tot_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def zipf_plot(sorted_ngrams,ngram):\n",
    "    x_axis=[ math.log(i) for i in range(1,len(sorted_ngrams)+1)]\n",
    "    y_axis= [ math.log(i[1]) for i in sorted_ngrams]\n",
    "    plt.clf()\n",
    "    plt.xlabel('Log rank')\n",
    "    plt.ylabel('Log frequency')\n",
    "    plt.title('Zipf\\'s law for {}'.format(ngram))\n",
    "    plt.plot(x_axis,y_axis)\n",
    "    plt.savefig('./zipf_{}.png'.format(ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_unigrams = unigram_counts.most_common()\n",
    "zipf_plot(sorted_unigrams,'unigrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_freq = []\n",
    "for w1 in bigram_counts:\n",
    "    for w2 in bigram_counts[w1]:\n",
    "        bigram_freq.append([(w1,w2),bigram_counts[w1][w2]])\n",
    "\n",
    "sorted_bigrams = sorted(bigram_freq , key = lambda x: x[1], reverse=True)\n",
    "zipf_plot(sorted_bigrams,'bigrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_freq = []\n",
    "for (w1,w2) in trigram_counts:\n",
    "    for w3 in trigram_counts[(w1,w2)]:\n",
    "        trigram_freq.append([(w1,w2,w3),trigram_counts[(w1,w2)][w3]])\n",
    "\n",
    "sorted_trigrams = sorted(trigram_freq , key = lambda x: x[1], reverse=True)\n",
    "zipf_plot(sorted_trigrams,'trigrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_sorted_bigrams = [bg for bg in sorted_bigrams if (bg[0][0]!=None and bg[0][1]!=None)]\n",
    "actual_sorted_trigrams = [tg for tg in sorted_trigrams if(not(tg[0][0]==None or tg[0][1]==None or tg[0][2]==None))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top ten unigrams, bigrams, trigrams\n",
    "print('Task 1 : N-gram models without smoothing\\n', file=outfile)\n",
    "print('\\nTop ten unigrams:', file=outfile)\n",
    "print(sorted_unigrams[:10], file=outfile)\n",
    "print('\\nTop ten bigrams:', file=outfile)\n",
    "print(actual_sorted_bigrams[:10], file=outfile)\n",
    "print('\\nTop ten trigrams:', file=outfile)\n",
    "print(actual_sorted_trigrams[:10], file=outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Scores of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('\\nUnigram test probabilities', file=outfile)\n",
    "for elem in test_sentences:\n",
    "    p_val=np.prod([unigram_model[i] for i in elem.split()])\n",
    "    print('Sequence: {:20} | Unigram prob: {:0.4e}| {}'.format(elem,p_val,MLE_perplexity(p_val,elem)), file=outfile)\n",
    "\n",
    "print('\\nBigram test probabilities', file=outfile)\n",
    "\n",
    "for elem in test_sentences:\n",
    "    p_val=1\n",
    "    for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        if(w1 in bigram_model):\n",
    "            if(w2 in bigram_model[w1]):\n",
    "                p_val*=bigram_model[w1][w2]\n",
    "                continue\n",
    "        p_val = 0\n",
    "        break\n",
    "    print('Sequence: {:20} | Bigram prob: {:.4e}| {}'.format(elem,p_val,MLE_perplexity(p_val,elem)), file=outfile)\n",
    "    \n",
    "\n",
    "print('\\nTrigram test probabilities', file=outfile)\n",
    "for elem in test_sentences:\n",
    "    p_val=1\n",
    "    for w1,w2,w3 in trigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        try:\n",
    "            p_val*=trigram_model[(w1,w2)][w3]\n",
    "        except Exception as e:\n",
    "            p_val=0\n",
    "            break\n",
    "    print('Sequence: {:20} | Trigram prob: {:.4e}| {}'.format(elem,p_val,MLE_perplexity(p_val,elem)), file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Laplacian smoothing\n",
    "\n",
    "k = [1e-4, 1e-3, 1e-2, 0.1, 1]\n",
    "print('###########################################', file=outfile)\n",
    "print('Task 2 : Laplacian Smoothing', file=outfile)\n",
    "\n",
    "for alpha in k:\n",
    "\n",
    "    print('\\nk = {} | Unigram model:'.format(alpha), file=outfile)\n",
    "    # unigrams\n",
    "    for elem in test_sentences:\n",
    "        p_val = 1\n",
    "        for w1 in elem.split():\n",
    "            if(w1 in unigram_model):\n",
    "                p_val *= unigram_model[w1]\n",
    "            else:\n",
    "                p_val *= 1/len(unigram_model)\n",
    "        print('Sequence: {:20} | Unigram prob: {:.4e}| {}'.format(elem,p_val,MLE_perplexity(p_val,elem)), file=outfile)\n",
    "\n",
    "    # bigrams\n",
    "    print('\\nk = {} | Bigram model:'.format(alpha), file=outfile)\n",
    "    N = len(sorted_unigrams)     # unseen test unigrams not taken into account\n",
    "    for elem in test_sentences:\n",
    "        p_val=1\n",
    "        for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "            if(w1 in bigram_counts):\n",
    "                t = sum(bigram_counts[w1].values())\n",
    "                if(w2 in bigram_counts[w1]):\n",
    "                    p_val *=  (alpha + bigram_counts[w1][w2])/(alpha*N + t)\n",
    "                else:\n",
    "                    p_val *= alpha/(alpha*N + t)\n",
    "            else:\n",
    "                p_val *= 1/N    \n",
    "        print('Sequence: {:20} | Bigram prob: {:.4e}| {}'.format(elem,p_val,MLE_perplexity(p_val,elem)), file=outfile)\n",
    "    \n",
    "    # trigrams\n",
    "    print('\\nk = {} | Trigram model:'.format(alpha), file=outfile)\n",
    "    N = N**2\n",
    "    for elem in test_sentences:\n",
    "        p_val=1\n",
    "        for w1,w2,w3 in trigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "            if((w1,w2) in trigram_counts):\n",
    "                t = sum(trigram_counts[(w1,w2)].values())\n",
    "                if(w3 in trigram_counts[(w1,w2)]):\n",
    "                    p_val *= (alpha + trigram_counts[(w1,w2)][w3])/(alpha*N + t)\n",
    "                else:\n",
    "                    p_val *= alpha/(alpha*N + t)\n",
    "            else:\n",
    "                p_val *= 1/N\n",
    "        print('Sequence: {:20} | Trigram prob: {:.4e}| {}'.format(elem,p_val,MLE_perplexity(p_val,elem)), file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-1932cb553b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdeno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mpGT_bigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_bigrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_keys' object does not support indexing"
     ]
    }
   ],
   "source": [
    "# good turing\n",
    "print('###########################################', file=outfile)\n",
    "print('Task 3 : Good Turing Smoothing\\n', file=outfile)\n",
    "total_possible_bigrams = (len(unigram_counts)+1)**2 # 1 to account for None\n",
    "deno = sum([i[1] for i in sorted_bigrams])\n",
    "n = {0:total_possible_bigrams-len(sorted_bigrams)}\n",
    "rev_bigrams = list(reversed(sorted_bigrams))\n",
    "for bg in rev_bigrams:\n",
    "    if(bg[1] not in n):\n",
    "        n[bg[1]] = 1\n",
    "    else:\n",
    "        n[bg[1]] += 1\n",
    "        \n",
    "counts = list(n.keys())\n",
    "for rank in range(0,len(counts)-1):\n",
    "    n[counts[rank]] = ((rank+1)*n[counts[rank+1]])/(n[counts[rank]]*deno)\n",
    "pGT_bigram = {None:{None:n[0]}}\n",
    "for bg in rev_bigrams:\n",
    "    if(bg[0][0] in pGT_bigram):\n",
    "        pGT_bigram[bg[0][0]][bg[0][1]] = n[bg[1]]\n",
    "    else:\n",
    "         pGT_bigram[bg[0][0]] = {bg[0][1]: n[bg[1]]}\n",
    "            \n",
    "print('Bigram model | GT probability for unseen bigrams = {}\\n'.format(pGT_bigram), file=outfile)\n",
    "for elem in test_sentences:\n",
    "    p_val=1\n",
    "    for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        if(w1 in pGT_bigram):\n",
    "            if(w2 in pGT_bigram[w1]):\n",
    "                p_val*=pGT_bigram[w1][w2]\n",
    "                continue\n",
    "        p_val *= pGT_bigram[None][None]\n",
    "    print('Sequence: {:20} | Bigram prob: {:.4e}| {}'.format(elem,p_val,MLE_perplexity(p_val,elem)), file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_possible_trigrams = (len(unigram_counts)+1)**3 # 1 to account for None\n",
    "n0 = total_possible_trigrams-len(sorted_trigrams)\n",
    "n1 = sum([1 for i in sorted_trigrams if i[1]==1])\n",
    "deno = sum([i[1] for i in sorted_trigrams])\n",
    "pGT_trigram = n1/(n0*deno)\n",
    "\n",
    "print('\\nTrigram model | GT probability for unseen trigrams = {}\\n'.format(pGT_trigram), file=outfile)\n",
    "for elem in test_sentences:\n",
    "    p_val=1\n",
    "    for w1,w2,w3 in trigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "        if((w1,w2) in trigram_model):\n",
    "            if(w3 in trigram_model[(w1,w2)]):\n",
    "                p_val*=trigram_model[(w1,w2)][w3]\n",
    "                continue\n",
    "        p_val *= pGT_trigram\n",
    "    print('Sequence: {:20} | Trigram prob: {:.4e}| {}'.format(elem,p_val,MLE_perplexity(p_val,elem)), file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MLE_perplexity(prob,test_sent):\n",
    "    if(prob==0):\n",
    "        return ('Log-likelihood: -inf | Perplexity: inf')\n",
    "    N = len(test_sent.split())\n",
    "    return ('Log-likelihood: {:0.4f} | Perplexity: {:0.4f}'.format(math.log(prob),pow(prob,-1/N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interpolation\n",
    "\n",
    "lamda = [0.2,0.5,0.8]\n",
    "print('###########################################', file=outfile)\n",
    "print('Task 4 : Interpolation Method', file=outfile)\n",
    "for l in lamda:\n",
    "    print('\\nLambda : {}'.format(l), file=outfile)\n",
    "    for elem in test_sentences:\n",
    "        p_val = 1 \n",
    "        for w1,w2 in bigrams(elem.split(),pad_left=True,pad_right=True):\n",
    "            p_bigram = 0        # for unseen bigrams\n",
    "            p_unigram = 0\n",
    "            if(w1 in bigram_model):\n",
    "                if(w2 in bigram_model[w1]):\n",
    "                    p_bigram = bigram_model[w1][w2]\n",
    "            if(w2 in unigram_model):\n",
    "                p_unigram = unigram_model[w2]\n",
    "            p_val *= (l*p_bigram + (1-l)*p_unigram)\n",
    "        print('Sequence: {:20} | Bigram prob: {:.4e}| {}'.format(elem,p_val,MLE_perplexity(p_val,elem)), file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
